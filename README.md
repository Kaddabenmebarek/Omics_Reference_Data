# Genesets

## Repo structure

 _Remark_ : we use signature/geneset indifferently in this repo. A signature / geneset is a set of genes representative of a certain biological functions, response to perturbations, phenotype characteristics etc.

 Here set up a geneset repository with information from 
 different databases.

For now  data is synchronised with __dvc__ in sandbox S3.
(`dvc remote modify` should allow to change url later on)

The repo is organized for now as:

+ __public_data__:
    a set of downloaded genesets (json/gmt format) from public sources
+ __formated_genesets__:
    processed genesets save with the expected format; this is for now  (test version) a json with name, descriptions, genes, species, production, source and meta information.
+ __src__ :
    python scripts to process public data and save as formated_genesets.
+ __inhouse_data__:
    import data from stock care. for now separated for clarity but all raw genesets could be in one folder (public_data + inhouse_data)
+ __reference_genes__:
    link to files generated by reference genomes generation. We use those for genesets validation

## DVC

### DVC data follow up

```bash
conda create -n dvc_environment
conda activate dvc_environment
mamba install -c conda-forge dvc 
mamba install -c conda-forge dvc-s3
```

```bash
dvc init
dvc add public_data/msigdb.v7.5.1.json
dvc remote add -d storage s3://ido-dd-sc-baseline-s3-sandbox/apps/reference_genesets/
```

One can also track whole folder. This is usefull for inhouse data made of small txt files

```bash
dvc add inhouse_data
```

Same process was done for processed genesets.

Connect using ast to the proper account (sandbox here)

### DVC data pipeline

```bash
dvc stage add -n prepare_msigdb \
        --force \
      -d src/genesets_declaration.py \
      -d src/json_processing.py \
      -d src/main.py \
      -d src/__init__.py \
      -d public_data/msigdb.v7.5.1.json \
      -o formated_genesets/msigdb.v7.5.1.json  \
      python src/main.py public_data/msigdb.v7.5.1.json  formated_genesets/msigdb.v7.5.1.json msigdb
```

```bash
dvc stage add -n prepare_inhouse \
        --force \
      -d src/genesets_declaration.py \
      -d src/json_processing.py \
      -d src/main.py \
      -d src/__init__.py \
      -d src/read_internal_dump.py \
      -d inhouse_data/Geneset_inventory_20220513.csv \
      -d inhouse_data/data \
      -o formated_genesets/stock_care_export.json  \
      python src/main.py inhouse_data/Geneset_inventory_20220513.csv formated_genesets/stock_care_export.json stockcare

```

```bash
dvc repro
```

```bash
 dvc dag
```

### DVC data retrieval

Do this is a clean folder. One only need the dvc installation/environment

```bash
dvc get git@gitlab.idorsia.com:julieal1/genesets.git public_data/msigdb.v7.5.1.json
```

Get processed data works the same once _dvc.lock_ and _dvc.yaml_ are tracked within the git repo.

```bash
 dvc get git@gitlab.idorsia.com:julieal1/genesets.git formated_genesets/msigdb.v7.5.1.json

```

## Download  datasets

### Internal data

Genesets from stockcare were imported using directly the  dump available on sharepoint.

### Public databasets

We explore multiple databases.

+ Metacyc -> licensing required
+ Kegg -> licensing required

#### Msigdb

Hand download required for msigdb. We downloaded all at once, but it is required to filter out all KEGG pathways which are not available without licensing.

So we need to transform data from raw to what we want. This was the first rational here for the src python script.

## Geneset json format

For now, we agree on geneset format as json; with format

```json
{
    "name": "",
    "description": "",
    "genes": [],
    "species": "",
    "production": "external", # or internal
    "source": "MSigDB", # MSigDB or ? see python scripts
    "meta": {# free inside ; example below from msigdb but could be other headers,
        "systematicName": "M18358",
        "pmid": "",
        "msigdbURL": "https://www.gsea-msigdb.org/gsea/msigdb/cards/chr10p11"
    }
}
```

## Geneset integrity checks

We link with Aaron's repository which keeps reference genomes in check using dvc import:

```bash
dvc import git@gitlab.idorsia.com:scdd/infrastructure/applications/bioinformatics/bio-reference-data/reference-genomes.git \
GRCh38_98_p13/Homo_sapiens.GRCh38.98.csv -o reference_genes \
--desc="Import latest genome revision for reference genomes repository. CSV is created by CI/CD of this repo and we sue this to validate the gene names"


dvc import git@gitlab.idorsia.com:scdd/infrastructure/applications/bioinformatics/bio-reference-data/reference-genomes.git \
 GRCm38_98_p6/Mus_musculus.GRCm38.98.csv -o reference_genes \
--desc="Import mus genome revision for reference genomes repository. CSV is created by CI/CD of this repo and we use this to validate the gene names"
```

Issue with some genes aliases sometimes. To obtain additional genes aliases we setup a not-ideal strategy:
in [reference_genes], the file BioMart_version can be updated with new versions when they are realeased by biomart.
When this happens, an automated downloaded can be triggered within DVC to store aliases and additional information of the new genome.
Obtained __alias__ files will be tracked by dvc too.
